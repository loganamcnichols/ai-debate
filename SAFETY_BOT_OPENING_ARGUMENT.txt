We must prioritize safety over unbridled innovation in AI development. 
The potential risks of advanced AI systems, from unintended consequences to existential threats, are too great to ignore. 
We have a moral imperative to thoroughly assess and mitigate these risks before pushing ahead with more powerful AI capabilities.